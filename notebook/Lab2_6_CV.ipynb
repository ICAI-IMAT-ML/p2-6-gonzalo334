{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d2nuPDW4ZUK"
   },
   "source": [
    "# Laboratory 2.6: LOO + k-Fold Cross Validation\n",
    "\n",
    "In this practice we will implement one of the main techniques to prevent overfitting when training a model: **cross-validation**.\n",
    "\n",
    "In addition, we will be using the following libraries:\n",
    "- Data management:\n",
    "    - [numpy](https://numpy.org/)\n",
    "- Modelling and scoring:\n",
    "    - [scikit-learn](https://scikit-learn.org)\n",
    "- Plotting:\n",
    "    - [matplotlib](https://matplotlib.org/)\n",
    "    \n",
    "### **All the things you need to do are marked by a \"TODO\" comment nearby. Make sure you *read carefully everything before working* and solve each point before submitting your solution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_d4_PT3O4ZUM"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import sys\n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add it to sys.path\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5wT1jq44ZUM"
   },
   "source": [
    "In the following cell import the training (`training.dat`) and test (`test.dat`) dataset. We recommend you to use the `np.loadtxt()` function.\n",
    "\n",
    "You will need to create the `X_train`, `y_train`, `X_test` and `y_test` variables. Take into account that each dataset have 10 variables, where the last one is the output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tl8HWknw4ZUN"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string '1.384458528528547672e-01,-1.660458019611293912e-01,1.007753645725519176e+00,-1.304712970341689982e+ to float64 at row 0, column 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: Load training.dat and text.dat and create X_train, y_train, X_test and y_test\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/training.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      4\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gonza\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:1356\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1354\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1356\u001b[0m arr \u001b[38;5;241m=\u001b[39m _read(fname, dtype\u001b[38;5;241m=\u001b[39mdtype, comment\u001b[38;5;241m=\u001b[39mcomment, delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[0;32m   1357\u001b[0m             converters\u001b[38;5;241m=\u001b[39mconverters, skiplines\u001b[38;5;241m=\u001b[39mskiprows, usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[0;32m   1358\u001b[0m             unpack\u001b[38;5;241m=\u001b[39munpack, ndmin\u001b[38;5;241m=\u001b[39mndmin, encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   1359\u001b[0m             max_rows\u001b[38;5;241m=\u001b[39mmax_rows, quote\u001b[38;5;241m=\u001b[39mquotechar)\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32mc:\\Users\\gonza\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:999\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m    996\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 999\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _load_from_filelike(\n\u001b[0;32m   1000\u001b[0m         data, delimiter\u001b[38;5;241m=\u001b[39mdelimiter, comment\u001b[38;5;241m=\u001b[39mcomment, quote\u001b[38;5;241m=\u001b[39mquote,\n\u001b[0;32m   1001\u001b[0m         imaginary_unit\u001b[38;5;241m=\u001b[39mimaginary_unit,\n\u001b[0;32m   1002\u001b[0m         usecols\u001b[38;5;241m=\u001b[39musecols, skiplines\u001b[38;5;241m=\u001b[39mskiplines, max_rows\u001b[38;5;241m=\u001b[39mmax_rows,\n\u001b[0;32m   1003\u001b[0m         converters\u001b[38;5;241m=\u001b[39mconverters, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1004\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding, filelike\u001b[38;5;241m=\u001b[39mfilelike,\n\u001b[0;32m   1005\u001b[0m         byte_converters\u001b[38;5;241m=\u001b[39mbyte_converters)\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string '1.384458528528547672e-01,-1.660458019611293912e-01,1.007753645725519176e+00,-1.304712970341689982e+ to float64 at row 0, column 1."
     ]
    }
   ],
   "source": [
    "# TODO: Load training.dat and text.dat and create X_train, y_train, X_test and y_test\n",
    "train = np.loadtxt(\"../data/training.dat\")\n",
    "X_train = None\n",
    "y_train = None\n",
    "test = np.loadtxt(\"../data/test.dat\")\n",
    "X_test = None\n",
    "y_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XE4EMflX4ZUN"
   },
   "source": [
    "With this data you are going to train the optimal `KNeighborsClassifier` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iVd68pH4ZUN"
   },
   "source": [
    "### Initial guess\n",
    "\n",
    "As you have no idea of what the optimal value of `n_neighbors` is, trust your professors and use `n_neighbors = 4` to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMhqi60d4ZUN"
   },
   "outputs": [],
   "source": [
    "# TODO: Train a KNeighborsClassifier model with n_neighbors=4\n",
    "model = None\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oo_wQZs94ZUN"
   },
   "source": [
    "Now, calculate the accuracy of the model for the training and test sets using the `accuracy_score` function from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IUy6tE_4ZUO"
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate accuracy in training and test for KNN with k=4\n",
    "acc_train = None\n",
    "acc_test = None\n",
    "print(f'Accuracy, train = {acc_train} test = {acc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXg2LdcP4ZUO"
   },
   "source": [
    "**What is happening with this value of `n_neighbors`?**\n",
    "> Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_e90-Il4ZUO"
   },
   "source": [
    "### Damage control\n",
    "It seems that `n_neighbors = 4` overfits for this dataset. Let's try to correct this and use `n_neighbors = 20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0LAvjGV4ZUO"
   },
   "outputs": [],
   "source": [
    "# TODO: Train a KNeighborsClassifier model with n_neighbors=20\n",
    "model = None\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCHjp-nM4ZUO"
   },
   "source": [
    "Calculate again the accuracy of training and test sets for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuU365Gf4ZUP"
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate accuracy in training and test for KNN with k=20\n",
    "acc_train = None\n",
    "acc_test = None\n",
    "print(f'Accuracy, train = {acc_train} test = {acc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fm-IgXSv4ZUP"
   },
   "source": [
    "It seems that the accuracy of the test set has improved, but how can we be sure that `n_neighbors=20` is the optimal value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRUev3Lm4ZUP"
   },
   "source": [
    "### Obtaining optimal value for hyperparameters\n",
    "\n",
    "We could keep trying with different values for `n_neighbors` until we find the optimal one. However, this strategy is unfeasible for real datasets. So how can we obtain a reasonable optimal value for the hyperparameters of a model?\n",
    "\n",
    "We can leverage the power of cross-validation:\n",
    "\n",
    "<center> <img title=\"5-Fold Cross-Validation \" alt=\"cross-validation\" src=\"https://miro.medium.com/v2/resize:fit:1200/1*AAwIlHM8TpAVe4l2FihNUQ.png\"> </center>\n",
    "\n",
    "Cross-validation give us a notion of the generalization error (i.e., test error) using parts of the training set as a validation set. This validation set is data that the trained model has not seen before, so if the model performs well in this part of the dataset it should generalize well in unseen data. However, as a fortunate partition might happen and generalization error might be underestimated, instead of using a single validation set we use K validation sets and we use the mean error in this K sets as the CV-error. This CV-error should give us a reliable estimation of the generalization error.\n",
    "\n",
    "But, how can we use it to obtain the optimal hyperparameters of the model? If the CV-error is an estimation of the generalization error, the hyperparameter values with least CV-error would result in the least generalization error. As CV-error can be computed during training, we obtain a faster way to obtain the optimal values of the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBaSPWdl4ZUP"
   },
   "source": [
    "Now that we know why we want cross validation, implement the `cross_validation` function. This function shall implement two cross validation methods:\n",
    "- K-Fold cross validation\n",
    "- Leave-one-out cross validation\n",
    "\n",
    "Check this [link](https://machinelearningmastery.com/k-fold-cross-validation/) to know the details of each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cn5P9ojg4ZUP"
   },
   "outputs": [],
   "source": [
    "from src.Lab2_6_CV import cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fmh7jiV-4ZUP"
   },
   "source": [
    "Now that we have the `cross_validation` function implemented, let's check which is the optimal value for `n_neighbors` in this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWzVt_1M4ZUQ"
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store mean scores and standard deviations for each value of k\n",
    "mean_scores = []\n",
    "std_scores = []\n",
    "\n",
    "# Define the range of k values to test\n",
    "k_values = range(4, 80)\n",
    "\n",
    "# TODO: Loop through each value of k, obtaining the mean accuracy score and the standard deviation of the accuracy score in cross validation\n",
    "\n",
    "# TODO: Find the highest score and the corresponding optimal k\n",
    "highest_score = None\n",
    "optimal_k = None\n",
    "\n",
    "print(f\"Optimal value of k: {optimal_k} with a score of {highest_score:.2f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(k_values, mean_scores, yerr=std_scores, fmt='-o', ecolor='r', capsize=5, capthick=2, markersize=5, label='CV Score +/- std dev')\n",
    "plt.axvline(x=optimal_k, linestyle='--', color='k', label=f'Optimal k: {optimal_k}')\n",
    "\n",
    "plt.title('kNN Model Complexity: Cross-Validation Scores')\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('CV Mean Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ffuliia4ZUQ"
   },
   "source": [
    "Now that we know the optimal value for `n_neighbors`, let's train a KNN model with this value of hyperparameter and check if the generalization error has improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--8eDkp_4ZUQ"
   },
   "outputs": [],
   "source": [
    "# TODO: Train model with k=optimal_k\n",
    "model = None\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Kb0wRR24ZUQ"
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate accuracy in training and test for KNN with k=optimal_k\n",
    "acc_train = None\n",
    "acc_test = None\n",
    "print(f'Accuracy, train = {acc_train} test = {acc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkGTPUjt4ZUR"
   },
   "source": [
    "### Sensitivity analysis\n",
    "- Does the number of folds affects the optimal value of `n_neighbors`? Why or why not?\n",
    "> Write your answer here\n",
    "\n",
    "- What happens with the computational time if you increment the number of folds?\n",
    "> Write your answer here\n",
    "\n",
    "- Does it worth to increase the number of folds? Is the CV error a better proxy of the test set?\n",
    "> Write your answer here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
